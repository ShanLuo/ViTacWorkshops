---
title: Home
layout: default
---
{% include figure.html img="ViTac2019.JPG" alt="intro image here" caption="ICRA 2019 Montreal" width="75%" %}

# ICRA 2019 ViTac Workshop: Integrating Vision and Touch for Multimodal and Cross-modal Perception

Abstract: Animals interact with the world through multimodal sensing inputs, especially vision and touch sensing in the case of humans. In contrast, artificial systems usually rely on a single sensing modality, with distinct hardware and algorithmic approaches developed for each modality, e.g. computer vision and tactile robotics. Future robots, as embodied agents, should make best use of all available sensing modalities to interact with the environment. Over the last few years, there have been advances in the fusing of information from distinct modalities and selecting between those modalities to use the most appropriate information for achieving a goal, e.g. grasping or manipulating an object. Furthermore, there has been a recent acceleration in the development of optical tactile sensors using cameras, such as the GelSight and TacTip tactile sensors, bridging the gap between vision and tactile sensing, and creating cross-modal perception. This workshop will encompass recent progress in the area of combining vision and touch sensing from the perspective of how touch sensing complements vision to achieve a better robot perception, exploration, learning and interaction with humans. The proposed full-day workshop aims to enhance active collaboration, discussion of methods for the fusion of vision and touch, discussion of challenges for multimodal and cross-modal sensing, development of optical tactile sensors and applications.

**Organisers:** <br>
[Shan Luo](https://shanluo.github.io/), University of Liverpool <br>
[Nathan Lepora](www.lepora.com), University of Bristol <br>
[Uriel Martinez Hernandez](https://researchportal.bath.ac.uk/en/persons/uriel-martinez-hernandez), University of Bath <br>
[João Bimbo](https://www.iit.it/people/joao-bimbo), Istituto Italiano di Tecnologia (IIT) <br>
[Huaping Liu](https://sites.google.com/site/thuliuhuaping/), Tsinghua University <br>

**Invited speakers:** <br>
●	Edward Adelson (MIT)  <br>
●	Peter Allen (Columbia University)  <br>
●	Alberto Rodriguez (MIT)  <br>
●	Oliver Kroemer (CMU)  <br>
●	Lorenzo Natale (IIT)  <br>
●	Vincent Hayward (UPMC Univ Paris)  <br>
●	Hongbin Liu (King’s College London)  <br>
●	Van Ho (Japan Adv. Institute of Science and Technology)  <br>

**Accepted papers** <br>
<ol>
  <li><a href="content/ICRA2019ViTac_paper_1.pdf">Giovanni Sutanto, Balakumar Sundaralingam, Yevgen Chebotar, Zhe Su, Ankur Handa, Nathan Ratliff and Dieter Fox. "Learning Latent Space Dynamics for Tactile Servoing" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_2.pdf">Alexander C. Abad and Anuradha Ranasinghe, "Pilot Study: Low Cost GelSight Sensor" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_3.pdf">Oliver Struckmeier, Kshitij Tiwari, Martin J. Pearson, and Ville Kyrki, "ViTa-SLAM: Biologically-Inspired Visuo-Tactile SLAM" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_4.pdf">Maria Bauza, Oleguer Canal and Alberto Rodriguez. "Tactile Mapping and Localization from High-Resolution Tactile Imprints" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_5.pdf">Hongzhuo Liang, Shuang Li, Xiaojian Ma, Norman Hendrich, Timo Gerkmann, Jianwei Zhang. "Making Sense of Audio Vibration for Liquid Height Estimation in Robotic Pouring" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_7.pdf">Teng Xue, Wenhai Liu, Mingshuo Han, Zhenyu Pan, Jin Ma, Quanquan Shao, Weiming Wang. "Bayesian Grasp:Vision based robotic stable grasp via prior tactile knowledge learning" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_8.pdf">Gyan Tatiya and Jivko Sinapov. "Sensorimotor Cross-Perception Knowledge Transfer for Grounded Category Recognition" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_9.pdf">Daniel Fernandes Gomes, Achu Wilson and Shan Luo. "GelSight Simulation for Sim2Real Learning" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_10.pdf">J. Monteiro, H. Araujo, M. Tavakoli, Amilcar Ramalho. "A Novel Sensor to Measure Surface Deformation and Contact Shape Using Stereo Vision" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_11.pdf">L.N. Vishnunandan Venkatesh, Jyothsna Padmakumar Bindu and Richard M Voyles. "Functional Inspection Using Tactile Perception during Manipulation of Deformable Objects" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_12.pdf">Gustavo Goretkin, Leslie Pack Kaelbling, Tomas Lozano-Perez. "Motion planning with visual and tactile sensing for safety in uncertain environments" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_13.pdf">Radhen Patel, Jacob Segil and Nikolaus Correll. "Reactive control of a robot hand equipped with visual-haptic sensor for pre-grasp shaping and gentle touch" </a></li>
  <li><a href="content/ICRA2019ViTac_paper_14.pdf">Timo Korthals , Andrew Melnik , Ju ̈rgen Leitner , and Marc Hesse. "Multisensory Assisted In-hand Manipulation of Objects with a Dexterous Hand" </a></li>
</ol>


We thank the support from the following IEEE RAS Technical Committees: <br>
-   Haptics <br>
-   Computer and Robot Vision <br>


<!-- 
{% include toc.html %}

------

{% include template/credits.html %} -->


