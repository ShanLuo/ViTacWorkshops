---
title: Home
layout: default
---

# ICRA 2020 ViTac Workshop: Closing the Perception-Action Loop with Vision and Tactile Sensing

**Abstract:**  Humans couple perception and action tightly with multimodal sensory inputs, especially vision and touch sensing. For example, moving your hands over an object’s surface enables you to see/feel its shape, temperature and texture with your eyes and the sense of touch in hands. In contrast, artificial systems usually lack the capability of using multimodal sensing to facilitate the perception and action in the same loop. Future robots, as embodied agents, should exploit all available sensing modalities to interact with the environment. In recent decades, there has been much advancement in both vision sensors and tactile sensors available for robots. Good example vision sensors are RGB webcams, depth sensors such as the Kinect and stereo cameras; tactile sensors include optical tactile sensors, such as the GelSight and TacTip, and modular tactile sensors for large body areas. This convergence between visual and tactile sensing technologies, offers new opportunities to fuse information to perform robot tasks, such as closed-loop active visuo-tactile perception when grasping/manipulating objects. The proposed full-day workshop will encompass recent progress in the area of combining vision and touch sensing for an integrated perception-action loop, aiming to enhance active collaboration and address challenges for this important topic and applications. <br>


**Organisers:** <br>
[Shan Luo](https://shanluo.github.io/), King's College London <br>
[Nathan Lepora](www.lepora.com), University of Bristol <br>
[Wenzhen Yuan](https://www.ri.cmu.edu/ri-faculty/wenzhen-yuan/), Carnegie Mellon University <br>
[Gordon Cheng](https://www.professoren.tum.de/en/cheng-gordon), Technische Universität München <br>

**Invited speakers:** <br>
●	Peter Allen​ (Columbia University) <br>
●	Dieter Fox​ (University of Washington and Nvidia) <br>
●	Vincent Hayward​ (UPMC Univ Paris) <br>
●	Alberto Rodriguez​ (MIT) <br>
●	Kaspar Althoefer​ (Queen Mary University of London) <br>
●	Huaping Liu​ (Tsinghua University) <br>
●	Robert Haschke​ (Bielefeld University) <br>
●	Lorenzo Natale​ (Istituto Italiano di Tecnologia) <br>

**Accepted papers** <br>
<ol>
  <li><a href="content/ICRA2020ViTac_paper_1.pdf">Maria Bauza, Eric Valls, Bryan Lim, Theo Sechopoulos, Alberto Rodriguez. "Object Pose Estimation with Geometric Tactile Rendering and Tactile Image Matching" </a></li>
  <li><a href="content/ICRA2020ViTac_paper_2.pdf">Fedor Chervinskii, Alexander Rybnikov, Damian Bogunowicz and Komal Vendidandi, "Sim2Real for Peg-Hole Insertion with Eye-in-Hand Camera" </a></li>
  <li><a href="content/ICRA2020ViTac_paper_3.pdf">Carmelo Sferrazza and Raffaello D’Andrea. "Accurate estimation of the 3D contact force distribution with an optical tactile sensor – Live demonstration" </a></li>
  <li><a href="content/ICRA2020ViTac_paper_4.pdf">Guanqun Cao and Shan Luo. "STAM: An Attention Model for Tactile Texture Recognition" </a></li>
  <li><a href="content/ICRA2020ViTac_paper_5.pdf">Daniel Fernandes Gomes, Zhonglin Lin, Shan Luo. "Exploiting Touch Sensing around Fingers" </a></li>
  <li><a href="content/ICRA2020ViTac_paper_6.pdf">Sudharshan Suresh, Joshua G. Mangelson, and Michael Kaess. "Incremental shape and pose estimation from planar pushing using contact implicit surfaces" </a></li>
</ol>


We thank the support from the following IEEE RAS Technical Committees: <br>
-   Haptics <br>
-   Cognitive Robotics <br>
-   Computer and Robot Vision <br>
-   Human-Robot Interaction & Coordination <br>


<!-- 
{% include toc.html %}

------

{% include template/credits.html %} -->

