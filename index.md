---
title: Home
layout: default
---

# ICRA 2024 Workshop on “Robot Embodiment through Visuo-Tactile Perception”

This is the official website for "ViTac 2024: Robot Embodiment through Visuo-Tactile Perception".

Abstract: This is the 5th time for us to organise the ViTac workshop in the ICRA conferences, after ICRA 2019, 2020, 2021 and 2023 ViTac Workshops. It will also be timely for us to report the progress of the Special Issue (now called Special Collection) we are organising on Tactile Robotics at the IEEE Transactions on Robotics. The recent trend in embodied intelligence, i.e., intelligence that requires and leverages a physical body of a robot, demands rich physical interactions with the surrounding environment, which cannot be achieved without perception of the environment with vision and tactile sensing. Recent years have seen rapid advancements in tactile sensor development, integration of information from visual and tactile modalities, leveraging vision and tactile sensing in agile grasping and manipulation, and simulations that involve both vision and tactile sensing. It will be timely to bring together the experts and young researchers in the field to discuss these important topics in robotics. This proposed full-day workshop will cover the recent advancements in the area of visuo-tactile sensing and perception, with the aim to empower robots with visual and tactile intelligence. It will further enhance active collaboration and address challenges for this important topic and applications.

For past ViTac workshops, please check [ViTac2023](https://shanluo.github.io/ViTacWorkshops/vitac2023).

**Time:** 13th / 17th May 2024
**Location:** Yokohama, Japan.

**Organisers:** <br>
[Shan Luo](https://shanluo.github.io/), King's College London <br>
[Nathan Lepora](www.lepora.com), University of Bristol <br>
[Wenzhen Yuan](https://cs.illinois.edu/about/people/adjunct-faculty/yuanwz), University of Illinois Urbana-Champaign <br>
[Rui Chen](https://callmeray.github.io/homepage/Home.html), Tsinghua University <br>
[Hao Su](https://cseweb.ucsd.edu/~haosu/ ), University of California San Diego <br>
[Kaspar Althoefer](http://www.eecs.qmul.ac.uk/profiles/althoeferkaspar.html), Queen Mary University of London <br>
[Gordon Cheng](https://www.professoren.tum.de/en/cheng-gordon), Technische Universität München <br>

**Invited speakers:** <br>
Antonio Bicchi, Italian Institute of Technology and the University of Pisa, Italy
Mark Cutkosky, Stanford University, USA
Roberto Calandra, Technische Universität Dresden, Germany
Huaping Liu, Tsinghua University, China
Perla Maiolino, University of Oxford, UK
Ravinder Dahiya, Northeast University, USA
Van Anh Ho, JAIST, Japan
Maria Bauza Villalonga, DeepMind

**Key dates** <br>
Posters and live demonstrations will be selected from a call for extended abstracts, reviewed by the organisers. The best posters will be invited to talk at the workshop. All submissions will be reviewed using a single-blind review process. Accepted contributions will be presented during the workshop as posters. Submissions must be sent in pdf, following the IEEE conference style (two-columns), to: shan.luo@kcl.ac.uk, indicating [ICRA 2024 Workshop] in the email subject. 
Submission Deadline: 15th March, 2024
Notification of acceptance: 30th March, 2024
Camera-ready deadline: 15th April, 2024
Workshop day: 13th May or 17th May 2024

The accepted papers will be invited to publish their accepted extended abstracts in Springer Nature conference proceedings series Lecture Notes in Computer Science (LNCS).

Topics of Interest:
●  	Development of tactile sensors for robot tasks
●  	Simulation of tactile sensors and Sim2Real learning
●  	Visual-tactile sensing and perception
The control and design of robotic visuo-tactile systems for human-robot interaction
Interactive visuo-tactile perception in robot grasping and manipulation 
Cognitive control of movement and sensory-motor representations with vision and touch
●  	Bio-inspired approaches and cognitive architectures for the visuo-tactile perception
●    Computational methods for processing vision and touch data in robot learning

We thank the support from the following IEEE RAS Technical Committees: <br>
-   Haptics <br>
-   Cognitive Robotics <br>
-   Human-Robot Interaction & Coordination <br>

<!-- 
{% include toc.html %}

------

{% include template/credits.html %} -->
